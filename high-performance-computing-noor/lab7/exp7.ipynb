{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MGCCmeoSw9e"
      },
      "source": [
        "CUDA: 1) Hello World Program  2) Vector Addition and 3) Vector Multiplication. Use input as a larger double number (64-bit). Run experiment for Threads = {1, 2, 4, 8, 16, 32, 64, 128, 256, 500} Estimate the parallelization fraction. \n",
        "Document it and report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVtrTvcDOJkX",
        "outputId": "07fe45ae-203f-4a60-a5cd-054f5c715937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-_74mwoc4\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-_74mwoc4\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=449378c7b3409e482a52f2f9df80bffcebcec8fe99c5b72381476716c73b090f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r5fo2si3/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCAC1sHdOXqo",
        "outputId": "b5c6008e-a01d-4e0a-869e-d9b6b77155dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%reload_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "directory /content/src already exists\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ucqdtAiOjKL",
        "outputId": "d642a710-a4b3-452c-e953-fe85bf86c354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%cu \n",
        "#include<bits/stdc++.h>\n",
        "using namespace std;\n",
        "int main() {\n",
        "    cout<<\"Hello This is Amar Kumar - CED17I029\"<<endl;\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello This is Amar Kumar - CED17I029\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4dwvpkqPmV4",
        "outputId": "69005f70-742b-4c1b-93e0-1f91d15011c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%cu\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) { \n",
        "  *c = *a + *b;\n",
        " }\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "using namespace std;\n",
        "int main(void) {\n",
        "  int a, b, c;   // host copies of a, b, c \n",
        "  int *d_a, *d_b, *d_c;  // device copies of a, b, c \n",
        "  int size = sizeof(int);\n",
        "  \n",
        "  // Allocate space for device copies of a, b, c\n",
        "  cudaMalloc((void **)&d_a, size);\n",
        "  cudaMalloc((void **)&d_b, size);\n",
        "  cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "  // Setup input values\n",
        "  a = 2;\n",
        "  b = 7;\n",
        "// Copy inputs to device\n",
        "  cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice); \n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice); \n",
        "\n",
        "  // Launch add() kernel on GPU\n",
        "  add<<<1,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    printf(\"Added Value = %d\", c);\n",
        "  // Cleanup\n",
        "  cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "  return 0;\n",
        " } "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Added Value = 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOftaCZZQvC-",
        "outputId": "5b255db2-ecf8-40fd-e1d6-16db9a77ff27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include<bits/stdc++.h>\n",
        "#include<chrono> \n",
        "using namespace std::chrono; \n",
        "using namespace std;\n",
        "#define N 100000\n",
        "#define M 1\n",
        "__global__ void vecAdd(double *a, double *b, double *c,int th){\n",
        "    int id = threadIdx.x;\n",
        "    for(int i=id ; i<N ; i+=th){\n",
        "        c[i] = a[i] + b[i];\n",
        "    }   \n",
        "}\n",
        " \n",
        "int main( int argc, char* argv[] ){\n",
        "    double *a,*b,*c;\n",
        "    double *d_a,*d_b,*d_c;\n",
        " \n",
        "    size_t size = N*sizeof(double);\n",
        "\n",
        "    a = (double*)malloc(size);\n",
        "    b = (double*)malloc(size);\n",
        "    c = (double*)malloc(size);\n",
        "\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        " \n",
        "    int i;\n",
        "    for( i = 0; i < N; i++ ) {\n",
        "        a[i] = rand()%100000 + (1.0/(rand()%1000));\n",
        "        b[i] = rand()%100000 + (1.0/(rand()%1000));\n",
        "    }\n",
        " \n",
        "    // Copy host vectors to device\n",
        "    cudaMemcpy( d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy( d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int tt[10] ={1,2,4,8,16,32,64,128,256,500}; \n",
        "    for(int t=0 ; t<10 ; ++t){\n",
        "        auto start = high_resolution_clock::now();\n",
        "        vecAdd<<<1, tt[t]>>>(d_a, d_b, d_c,tt[t]);\n",
        "        auto stop = high_resolution_clock::now(); \n",
        "        auto duration = duration_cast<microseconds>(stop - start); \n",
        "    // cout << \"Time taken by function: \"<< duration.count() << \" microseconds\" << endl; \n",
        "        cout <<duration.count()<<endl;\n",
        "    }\n",
        "    \n",
        "    //printf(\"execution time : %lf\\n\",(end-start));\n",
        "    cudaMemcpy( c, d_c, size, cudaMemcpyDeviceToHost );\n",
        " \n",
        "    //for(i=0; i<N; i++)\n",
        "      //printf(\"%lf + %lf = %lf \\n\",a[i],b[i],c[i]);\n",
        " \n",
        "    // Release device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        " \n",
        "    // Release host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        " \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n",
            "12\n",
            "7\n",
            "6\n",
            "4\n",
            "5\n",
            "6\n",
            "5\n",
            "6\n",
            "5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t42wMpU9sR9R",
        "outputId": "acf9989f-491b-4353-fa36-ab533805227a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include<bits/stdc++.h>\n",
        "#include<chrono> \n",
        "using namespace std::chrono; \n",
        "using namespace std;\n",
        "#define N 100000\n",
        "#define M 1\n",
        "__global__ void vecAdd(double *a, double *b, double *c,int th){\n",
        "    int id = threadIdx.x;\n",
        "    for(int i=id ; i<N ; i+=th){\n",
        "        c[i] = a[i] * b[i];\n",
        "    }   \n",
        "}\n",
        " \n",
        "int main( int argc, char* argv[] ){\n",
        "    double *a,*b,*c;\n",
        "    double *d_a,*d_b,*d_c;\n",
        " \n",
        "    size_t size = N*sizeof(double);\n",
        "\n",
        "    a = (double*)malloc(size);\n",
        "    b = (double*)malloc(size);\n",
        "    c = (double*)malloc(size);\n",
        "\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        " \n",
        "    int i;\n",
        "    for( i = 0; i < N; i++ ) {\n",
        "        a[i] = rand()%100000 + (1.0/(rand()%1000));\n",
        "        b[i] = rand()%100000 + (1.0/(rand()%1000));\n",
        "    }\n",
        " \n",
        "    // Copy host vectors to device\n",
        "    cudaMemcpy( d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy( d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int tt[10] ={1,2,4,8,16,32,64,128,256,500}; \n",
        "    \n",
        "    for(int t=0 ; t<10 ; ++t){\n",
        "        auto start = high_resolution_clock::now();\n",
        "        vecAdd<<<1, tt[t]>>>(d_a, d_b, d_c,tt[t]);\n",
        "        auto stop = high_resolution_clock::now(); \n",
        "        auto duration = duration_cast<microseconds>(stop - start); \n",
        "    // cout << \"Time taken by function: \"<< duration.count() << \" microseconds\" << endl; \n",
        "        cout <<duration.count()<<endl;\n",
        "    }\n",
        "    \n",
        "    //printf(\"execution time : %lf\\n\",(end-start));\n",
        "    cudaMemcpy( c, d_c, size, cudaMemcpyDeviceToHost );\n",
        " \n",
        "    for(i=0; i<N; i++)\n",
        "      printf(\"%lf * %lf = %lf \\n\",a[i],b[i],c[i]);\n",
        " \n",
        "    // Release device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        " \n",
        "    // Release host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        " \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "10\n",
            "6\n",
            "6\n",
            "5\n",
            "5\n",
            "6\n",
            "5\n",
            "5\n",
            "6\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXM7hsjssTgy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}